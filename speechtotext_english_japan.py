import azure.cognitiveservices.speech as speechsdk
import os
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.microsoft import EdgeChromiumDriverManager
import threading
from bs4 import BeautifulSoup
import pandas as pd
from googletrans import Translator
import asyncio
import shutil

speech_key = "#speech_key#"
service_region = "eastus"
language = 'ko-KR'

should_stop = False
upload_thread = None
driver = None

def connect_to_existing_browser():
    """ê¸°ì¡´ ì—£ì§€ ë¸Œë¼ìš°ì €ì— ì—°ê²°"""
    options = webdriver.EdgeOptions()
    options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
    
    try:
        # WebDriver ìƒì„±
        return webdriver.Edge(
            service=Service(EdgeChromiumDriverManager().install()),
            options=options
        )
    except Exception as e:
        print(f"ë¸Œë¼ìš°ì € ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ì—£ì§€ ë¸Œë¼ìš°ì €ë¥¼ --remote-debugging-port=9222 ì˜µì…˜ìœ¼ë¡œ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

def browser_connect() :
    global should_stop, driver
    try:
        # ê¸°ì¡´ ë¸Œë¼ìš°ì €ì— ì—°ê²°
        if driver is None:
            driver = connect_to_existing_browser()
            if driver is None:
                return
            time.sleep(2)  # ì—°ê²° ëŒ€ê¸°

        # 1. iframeì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        iframe = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.ID, "gradio-iframe"))
        )

        # 2. iframe ë‚´ë¶€ë¡œ ì´ë™
        driver.switch_to.frame(iframe)

    except Exception as e:
        print(f"âŒ Error in upload automation: {e}")

def upload_image_automation():
    global should_stop, driver
    
    # ì—…ë¡œë“œí•  ì´ë¯¸ì§€ í´ë”
    IMAGE_FOLDER = "C:/Users/volav/ms_doeun/2025.02/1stProject12team/images"
    # ìœ íš¨í•œ ì´ë¯¸ì§€ í™•ì¥ì
    VALID_EXTENSIONS = (".jpg", ".jpeg", ".png", ".bmp", ".gif")
    
    image_files = [
        os.path.join(IMAGE_FOLDER, f) 
        for f in os.listdir(IMAGE_FOLDER) 
        if f.endswith(VALID_EXTENSIONS)
    ]

    if not image_files:
        print("âŒ No images found in the folder.")
        return

    for i, image_path in enumerate(image_files, 1):
        if should_stop:
            print("ğŸ›‘ Upload process stopped by user")
            break

        print(f"ğŸ“¤ Uploading {i}/{len(image_files)}: {os.path.basename(image_path)}...")
        
        try:
            # 3. íŒŒì¼ ì—…ë¡œë“œ input ìš”ì†Œ ì°¾ê¸°
            file_input = WebDriverWait(driver, 2).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='file']"))
            )
            
            file_input.send_keys(image_path)
            print(f"âœ… Upload successful!")
            time.sleep(5)  # ì—…ë¡œë“œ ëŒ€ê¸°
        
            source_path = image_path
            destination_folder = "C:/Users/volav/ms_doeun/2025.02/1stProject12team/temp"
            shutil.move(source_path, destination_folder)

        except Exception as e:
            print(f"âŒ Error uploading {image_path}: {e}")
            continue

        finally:
            global upload_thread
            upload_thread = None


def scrape_table_data():
    """ì›¹í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    global driver
    if driver is None:
        return None
    
    iframe_html = driver.page_source
    # í˜„ì¬ ì—´ë¦° ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
    soup = BeautifulSoup(iframe_html, "html.parser")

    # í…Œì´ë¸” ì°¾ê¸°    
    tables = soup.find_all("table", class_="table svelte-y11bhb")

    if len(tables) < 2:
        print("í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return None

    # ì²« ë²ˆì§¸ í…Œì´ë¸” ì²˜ë¦¬
    headers1 = [th.text.strip() for th in tables[0].find_all("th")]
    rows1 = [[td.text.strip() for td in tr.find_all("td")] for tr in tables[0].find_all("tr")[1:]]
    df_1 = pd.DataFrame(rows1, columns=headers1)

    # ë‘ ë²ˆì§¸ í…Œì´ë¸” ì²˜ë¦¬
    headers2 = [th.text.strip() for th in tables[1].find_all("th")]
    rows2 = [[td.text.strip() for td in tr.find_all("td")] for tr in tables[1].find_all("tr")[1:]]
    df_2 = pd.DataFrame(rows2, columns=headers2)

    # CSV íŒŒì¼ ì €ì¥
    df_1.to_csv('df_1.csv', index=False, encoding='utf-8-sig')
    df_2.to_csv('df_2.csv', index=False, encoding='utf-8-sig')
    
    return df_1, df_2


def countdf_to_text(countdf) :
    def format_quality(quality):
        if "ì‹ ì„ í•´ìš”" in quality:
            return "ì‹ ì„ í•œ"
        elif "ë–¨ì´" in quality:
            return "ì €í’ˆì§ˆ"
        elif "ë²„ë ¤" in quality:
            return "ë²„ë¦´"
        return quality  # ê¸°íƒ€ ê²½ìš° ì²˜ë¦¬

    # ìš”ì•½ ë¬¸ì¥ ìƒì„±
    summary = [f"{format_quality(row['í’ˆì§ˆ'])} {row['í’ˆëª©']} {row['ê°œìˆ˜']}ê°œ"
            for _, row in countdf.iterrows()]

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    result = ", ".join(summary)
    return result + "ì…ë‹ˆë‹¤."


def pricedf_to_text(pricedf) :
    # ìƒíƒœ ë³€í™˜ í•¨ìˆ˜
    def format_status(status):
        if status == "fr":
            return "ì‹ ì„ í•œ"
        elif status == "low":
            return "ì €í’ˆì§ˆ"
        return status  # ê¸°íƒ€ ìƒíƒœ ì²˜ë¦¬ ê°€ëŠ¥

    # í’ˆëª©ë³„ & ìƒíƒœë³„ ê·¸ë£¹í™”
    grouped = pricedf.groupby(["í’ˆëª©", "ìƒíƒœ"])

    # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    sentences = []

    for (item, status), group in grouped:
        status_text = format_status(status)
        max_price = group["ë„ë§¤ê°€ê²©"].max()  # ìµœê³  ê°€ê²© ì°¾ê¸°
        max_rows = group[group["ë„ë§¤ê°€ê²©"] == max_price]  # ìµœê³  ê°€ê²©ê³¼ ê°™ì€ í–‰ ì°¾ê¸°
        regions = ", ".join(max_rows["ì§€ì—­"].tolist())  # ì§€ì—­ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°
        unit = max_rows["ë‹¨ìœ„"].iloc[0]  # ë‹¨ìœ„ ê°€ì ¸ì˜¤ê¸°

        sentence = (f"{status_text} {item}ì˜ ê²½ìš°, {unit} ë‹¨ìœ„ë¡œ íŒë§¤ë˜ê³  ìˆìœ¼ë©° "
                    f"í˜„ì¬ {regions}ì—ì„œ ê°€ì¥ ë†’ì€ ë„ë§¤ê°€ê²© {max_price}ì›ì— ê±°ë˜ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
        sentences.append(sentence)
    sentence_sum = ''
    for str in sentences :
        sentence_sum += str +' '
    return sentence_sum


def click_download(str):
    global driver
    
    if str == "ê°œìˆ˜" :
        component = "component-12"
    elif str == "ê°€ê²©" :
        component = "component-13"

    try:        
        button = WebDriverWait(driver, 7).until(
            EC.presence_of_element_located((By.ID, component))
            )
        time.sleep(1)
        button.click()

    except Exception as e:
        print(f"âŒ Error in click download: {e}")


async def translate_text(text, src_lang, dest_lang):
    translator = Translator()
    translated = await translator.translate(text, src=src_lang, dest=dest_lang)
    return translated.text





def speech_recognize_continuous_async_from_microphone():
    global should_stop, upload_thread, driver, language
    loop = asyncio.get_event_loop()

    def create_speech_recognizer(lang):
        speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region, speech_recognition_language=lang)
        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
        return speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    
    def create_speech_synthesizer(voice_name):
        speech_config2 = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
        speech_config2.speech_synthesis_voice_name = voice_name
        return speechsdk.SpeechSynthesizer(speech_config=speech_config2)
    
    voice_name = "ko-KR-JiMinNeural"
    speech_recognizer = create_speech_recognizer(language)
    speech_synthesizer = create_speech_synthesizer(voice_name)
    done = False
    
    
    def recognizing_cb(evt: speechsdk.SpeechRecognitionEventArgs):
        return
    
    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):
        nonlocal speech_recognizer, speech_synthesizer, done, voice_name  
        global should_stop, upload_thread, language
        
        print(f"ì¸ì‹ëœ ë§: {evt.result.text}")
        
        # ì–¸ì–´ ë³€ê²½ ë¡œì§
        if "ì˜ì–´" in evt.result.text or "ì‰ê¸€ë¦¬ì‰¬" in evt.result.text or "ì‰ê¸€ë¦¬ì‹œ" in evt.result.text or "è‹±èª" in evt.result.text or "english" in evt.result.text.lower():
            language = "en-US"
            print("Switching to English mode...")
            speech_recognizer.stop_continuous_recognition_async()
            speech_recognizer = create_speech_recognizer(language)
            setup_event_handlers(speech_recognizer)
            speech_recognizer.start_continuous_recognition_async()
            voice_name = "en-US-AndrewMultilingualNeural"
            speech_synthesizer = create_speech_synthesizer(voice_name)
            speech_synthesizer.speak_text_async("Switched to English mode")
            return
        
        elif "í•œêµ­ì–´" in evt.result.text or "korean" in evt.result.text.lower() or "éŸ“å›½èª" in evt.result.text or "kankokugo" in evt.result.text.lower() :
            language = "ko-KR"
            print("í•œêµ­ì–´ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            speech_recognizer.stop_continuous_recognition_async()
            speech_recognizer = create_speech_recognizer(language)
            setup_event_handlers(speech_recognizer)
            speech_recognizer.start_continuous_recognition_async()
            voice_name = "ko-KR-JiMinNeural"
            speech_synthesizer = create_speech_synthesizer(voice_name)
            speech_synthesizer.speak_text_async("í•œêµ­ì–´ ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤")
            return

        elif "æ—¥æœ¬èª" in evt.result.text or "japanese" in evt.result.text.lower() or "ì¼ë³¸ì–´" in evt.result.text or "nihongo" in evt.result.text.lower() :
            language = "ja-JP"
            print("æ—¥æœ¬èªãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
            speech_recognizer.stop_continuous_recognition_async()
            speech_recognizer = create_speech_recognizer(language)
            setup_event_handlers(speech_recognizer)
            speech_recognizer.start_continuous_recognition_async()
            voice_name = "ja-JP-NanamiNeural"
            speech_synthesizer = create_speech_synthesizer(voice_name)
            speech_synthesizer.speak_text_async("æ—¥æœ¬èªãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
            return
            
        if "ë" in evt.result.text.lower() or "end" in evt.result.text.lower() or "çµ‚ã‚ã‚Š" in evt.result.text.lower():
            print("Stop command recognized. Stopping recognition...")
            done = True
            speech_recognizer.stop_continuous_recognition_async()
        
        elif "ì‹œì‘" in evt.result.text.lower() or "start" in evt.result.text.lower() or "é–‹å§‹" in evt.result.text.lower():
            print("Start classification of Image")
            if language == "ko-KR":
                text = "ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
            elif language == "en-US":
                text = "Starting image classification"
            else:
                text = "ç”»åƒåˆ†é¡ã‚’é–‹å§‹ã—ã¾ã™"
            speech_synthesizer.speak_text_async(text)
            time.sleep(1)
            should_stop = False
            if upload_thread is None or not upload_thread.is_alive():
                upload_thread = threading.Thread(target=upload_image_automation)
                upload_thread.start()

        elif "ì •ì§€" in evt.result.text.lower() or "stop" in evt.result.text.lower() or "çµ‚äº†" in evt.result.text.lower():
            print("Stop classification of Image")
            text = "ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ì •ì§€í•©ë‹ˆë‹¤."
            if language == "ko-KR":
                texttranslated = text
            elif language == "en-US":
                src_lang = 'ko'
                dest_lang = 'en'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang) )
              
            else:
                src_lang = 'ko'
                dest_lang = 'ja'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            speech_synthesizer.speak_text_async(texttranslated)
            should_stop = True
        
        elif "ë§í•´ì¤˜" in evt.result.text or "tell me" in evt.result.text.lower() or "æ•™ãˆã¦" in evt.result.text.lower():
            print("í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.")
            countdf, pricedf = scrape_table_data()
            counttext = countdf_to_text(countdf)
            pricetext = pricedf_to_text(pricedf)
            if language == "ko-KR":
                texttranslated = "í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤." + counttext + pricetext
                             
            elif language == "en-US":
                text = "í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤." + counttext + pricetext
                src_lang = 'ko'
                dest_lang = 'en'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            else:
                text = "í˜„ì¬ê¹Œì§€ì˜ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤." + counttext + pricetext 
                src_lang = 'ko'
                dest_lang = 'ja'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            speech_synthesizer.speak_text_async(texttranslated)

        if "ì•ˆë…•" in evt.result.text or "hello" in evt.result.text.lower() or "ãŠã„" in evt.result.text.lower():
            text = "ì–´ì„œì˜¤ì„¸ìš”. ì‚¬ì¥ë‹˜. ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ì‹œì‘í•˜ì‹œë ¤ë©´ 'ì‹œì‘'ì´ë¼ê³  ë§í•´ì£¼ì„¸ìš”"
            if language == "ko-KR":
                texttranslated = text
                             
            elif language == "en-US":
                src_lang = 'ko'
                dest_lang = 'en'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            else:
                src_lang = 'ko'
                dest_lang = 'ja'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            speech_synthesizer.speak_text_async(texttranslated)

        if "ë‹¤ìš´ë¡œë“œ" in evt.result.text or "ë‹¤ìš´" in evt.result.text or "download" in evt.result.text.lower() or "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰" in evt.result.text :
            text = "ê°œìˆ˜ ì •ë³´ì™€ ê°€ê²© ì •ë³´ íŒŒì¼ì„ ë‹¤ìš´ë°›ìŠµë‹ˆë‹¤."
            if language == "ko-KR":
                texttranslated = text
                             
            elif language == "en-US":
                src_lang = 'ko'
                dest_lang = 'en'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            else:
                src_lang = 'ko'
                dest_lang = 'ja'
                texttranslated = loop.run_until_complete(translate_text(text, src_lang, dest_lang))
            click_download('ê°œìˆ˜')
            click_download('ê°€ê²©')
            speech_synthesizer.speak_text_async(texttranslated)

    def stop_cb(evt: speechsdk.SessionEventArgs):
        nonlocal done  # nonlocal ì„ ì–¸ì„ í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ìœ¼ë¡œ ì´ë™
        print('CLOSING on {}'.format(evt))
        done = True
    
    def setup_event_handlers(recognizer):
        recognizer.recognizing.connect(recognizing_cb)
        recognizer.recognized.connect(recognized_cb)
        recognizer.session_stopped.connect(stop_cb)
        recognizer.canceled.connect(stop_cb)
    
    setup_event_handlers(speech_recognizer)
    result_future = speech_recognizer.start_continuous_recognition_async()
    result_future.get()
    print('Continuous Recognition is now running. Say something...')
    print('Say "stop" to end the recognition')
    
    while not done:
        time.sleep(0.1)
    
    print("Recognition stopped, main thread can exit now.")



if __name__ == "__main__":
    print("ì‹œì‘í•˜ê¸° ì „ì— ì—£ì§€ ë¸Œë¼ìš°ì €ë¥¼ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
    print('msedge.exe --remote-debugging-port=9222')
    print("ë¸Œë¼ìš°ì €ê°€ ì‹¤í–‰ë˜ë©´ Gradio ì›¹í˜ì´ì§€ë¡œ ì´ë™í•œ í›„ ì´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    browser_connect() 

    try:        
        speech_recognize_continuous_async_from_microphone()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Script terminated by user")
        should_stop = True
    except Exception as e:
        print(f"\nâŒ Unexpected error: {e}")
        should_stop = True
    finally:
        if driver:
            driver.switch_to.default_content()
            driver.quit()